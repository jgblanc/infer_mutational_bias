---
title: "STAN_model"
author: "Jennifer Blanc"
date: "4/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(rstan)
library(data.table)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
set.seed(407)
```

## Model   

Model:  

$$\vec{\hat{\beta}} = \vec{\beta_T} + \sum_i \lambda_i^{-1/2} \vec{V} \beta_i + \vec{e}$$  

$$D_l = 1 \text{   if  } \beta_l > 0$$
$$D_l = 0 \text{   if  } \beta_l < 0$$  

$$R = \sum_lD_l$$  

$$R \sim Bin(1/2, L)$$

For a single site:  

$$\hat{\beta} = \beta + \sum_i \lambda_i^{-1/2} V \beta_i + e$$

## Functions to Simulate Data  

Function to simulate SNP loadings:  
* n = number of PCs
* L = number of SNPs
* loading_mean = used to skew the loadings 
* loading_sd = standard deviation used to draw loadings  
```{r}
simulate_loadings <- function(L, n, loading_mean, loading_sd) {
  loadings <- matrix(0, ncol = L, nrow = n)
  for (i in 1:n) {
   loadings[i,] <- rnorm(L, mean = loading_mean, sd = loading_sd) # skew mean
  }
  return(loadings)
}
``` 

Function to simulate Beta hats:  
* n = number of PCs
* L = number of SNPs
* Bpc = the true value of $\beta_{PC}$  
* epsilon_sd = standard deviation of the error
* loadings = SNP loadings simulated above

```{r}
calc_beta_hat <- function(L, n, Btrue, Bpc, epsilon_sd, loadings) {
  Bhat <- rep(0, L)
  mat <- matrix(NA, ncol = L, nrow = n)
  for (i in 1:n) {
    mat[i,] <- Bpc[i] * loadings[i,]
  }
  loading_time_pc <- colSums(mat)
  Bhat <- Btrue + loading_time_pc + rnorm(L, mean = 0, sd = epsilon_sd)
  return(Bhat)
}
```


## STAN model 

```{stan, output.var="simple", eval=T}
functions {  
  real my_ll_lpmf(int R, int L, real b){
    real lprob;
    lprob = lchoose(L, R) + (R*log(b)) + ((L - R)*log(1 - b));
    return lprob;
  }
}
data {
  int<lower=0> L;   // number of Beta hats
  int<lower=0> n;   // number of predictors (PCs)
  matrix[L, n] x;   // predictor matrix (loadings n x L)
  vector[L] y;      // outcome vector
  real b; // 
}
parameters {
  vector[n] beta;       // coefficients for predictors
  real<lower=0> sigma;  // error scale
}
model {
  int R;
  vector[L] est_beta;
  real true_causal;
  R = 0;
  est_beta = x*beta;
  for (i in 1:L) {
    true_causal = y[i] - est_beta[i];
    if (true_causal > 0) {
      R = R + 1;
    }
  };
  R ~ my_ll_lpmf(L, b); 
  //print("R:", R, "true_beta:", true_beta);
  //print("R:", R);
  y ~ normal(x * beta, sigma);  // likelihood
}
```

## Fit model 

Function to fit model 
```{r, warning=FALSE}
fit_model <- function(L, n, loading_mean, loading_sd, Bpc, epsilon_sd, Btrue, b) {
  loadings <- simulate_loadings(L = L, n = n, loading_mean = loading_mean, loading_sd = loading_sd)
  Bhat <- calc_beta_hat(L = L, n = n, Btrue = Btrue, Bpc = Bpc, epsilon_sd = epsilon_sd, loadings = loadings)
  data <- list(y = Bhat, L = L, n = n, x = t(loadings), b=b)
  fit <- sampling(simple, data = data, chains=4, refresh = 0) #refresh = 0
  return(fit)
}
```


## Examples  

1 PC with no effect 
```{r}
mod <- fit_model(L = 1000, n = 1, loading_mean = 1, loading_sd = 1, Bpc = 0, epsilon_sd = 1, Btrue = rep(0, 1000), b=0.5)
```

```{r}
fit_ss <- extract(mod)
hist(fit_ss$beta, main = "Posterior")
abline(v=0,col="red")
```

1 PC with Bpc = 2 
```{r, results="hide"}
mod <- fit_model(L = 1000, n = 1, loading_mean = 1, loading_sd = 1, Bpc = 2, epsilon_sd = 1, Btrue = rep(0, 1000), b=0.5)
```

```{r}
fit_ss <- extract(mod)
hist(fit_ss$beta, main = "Posterior")
abline(v=2,col="red")
```

4 PCs no effects 
```{r}
mod <- fit_model(L = 1000, n = 4, loading_mean = 1, loading_sd = 1, Bpc = rep(0,4), epsilon_sd = 1, Btrue = rep(0, 1000), b=0.5)

fit_ss <- extract(mod)
beta <- fit_ss$beta
par(mfrow = c(2,2))
hist(beta[,1])
abline(v=0,col="red")
hist(beta[,2])
abline(v=0,col="red")
hist(beta[,3])
abline(v=0,col="red")
hist(beta[,4])
abline(v=0,col="red")
```

4 PCs - PC 2 has effect = -2 
```{r}
mod <- fit_model(L = 1000, n = 4, loading_mean = 1, loading_sd = 1, Bpc = c(0,-2,0,0), epsilon_sd = 1, Btrue = rep(0, 1000), b=0.5)
 
fit_ss <- extract(mod)
beta <- fit_ss$beta
par(mfrow = c(2,2))
hist(beta[,1])
abline(v=0,col="red")
hist(beta[,2])
abline(v=-2,col="red")
hist(beta[,3])
abline(v=0,col="red")
hist(beta[,4])
abline(v=0,col="red")
```




## Real Loading Data 

Now that we have tested our model on simulated data, let's use real SNP loadings and eigenvalues but stick with a simulated GWAS where there are no true causal SNPs. We will run the model for 1,000 SNPs and n=10 PCs 

```{r}
# Load SNP Loadings + Eigenvalues 
gwas <- fread("../output/GWAS_ATLAS_ANNOTATED/test_loadings.txt")
evals <- fread("../output/GWAS_ATLAS_ANNOTATED/EUR_0.01.eigenval")

# Take 1,000 SNPS and only the loadings
loadings <- as.matrix(gwas[1:1000,21:30])

# Mean Loading for all 10 PCs
colMeans(loadings)

# Simulate a set of Beta Hats with all Bpc = 0
Bhat <- calc_beta_hat(L=nrow(loadings), n=10, Btrue = rep(0,nrow(loadings)), Bpc = rep(0,10), epsilon_sd = 1, loadings = t(loadings))

# Weight loadings by sqrt(eigenvalue)
wloadings <- loadings
for (i in 1:10) {
  wloadings[,i] <- as.numeric(sqrt(evals[i,1])) * loadings[,i]
}

# Fit Model 
data <- list(y = Bhat, L = nrow(wloadings), n = 10, x = loadings, b=0.5)
fit <- sampling(simple, data = data, chains=4, refresh = 0)
```

```{r}
# Extract posterior samples
fit_ss <- extract(fit)$beta

# Posterior Means
bpos <- colMeans(fit_ss)
bpos

# Calculate True Effect Sizes (should be 0)
true <- Bhat -  wloadings %*% bpos
hist(true)
```

Now let's repeat the whole process but also simulate a stratification effect along PC 2 $\beta_{PC2} = 1$
```{r}
# Simulate a set of Beta Hats with all Bpc = 0
Bpc <- rep(0,10)
Bpc[2] <- 1
Bhat <- calc_beta_hat(L=nrow(loadings), n=10, Btrue = rep(0,nrow(loadings)), Bpc = Bpc, epsilon_sd = 1, loadings = t(loadings))

# Fit Model 
data <- list(y = Bhat, L = nrow(wloadings), n = 10, x = loadings, b=0.5)
fit <- sampling(simple, data = data, chains=4, refresh = 0 )
```

```{r}
# Extract posterior samples
fit_ss <- extract(fit)$beta

# Posterior Means
bpos <- colMeans(fit_ss)
bpos

# Calculate True Effect Sizes (should be 0)
true <- Bhat -  wloadings %*% bpos
hist(true)
```

## Real GWAS Data  

Finally, we will use actual GWAS effect size estimates. Like the loadings, all effect sizes have been polarized to be the effect of the derived allele. For now, we will run the model on a single LD block (num_snps = 1368) with 10 principal components.  

```{r}
# Pick single LD block
gwas_block <- subset(gwas, gwas$LD_Block == 653)

# Mean Loading 
loadings <- as.matrix(gwas_block[,21:30])
colMeans(loadings)

# Look at Manhattan Plot 
dat <- gwas_block[,c("BP", "P", "Risk_Derived", "RAF", "ES_Derived")]
ggplot(dat, aes(x=BP,y=-log10(P), col = Risk_Derived)) + geom_point()
ggplot(dat, aes(x=RAF,y=abs(ES_Derived), col = Risk_Derived)) + geom_point()
```

```{r}
# Weight loadings by sqrt(eigenvalue)
wloadings <- loadings
for (i in 1:10) {
  wloadings[,i] <- as.numeric(sqrt(evals[i,1])) * loadings[,i]
}

# Fit Model 
data <- list(y = gwas_block$ES_Derived, L = nrow(wloadings), n = 10, x = loadings, b=0.5)
#fit <- sampling(simple, data = data, chains=4)
#saveRDS(fit,"~/Desktop/stan_block653")
```

```{r}
fit <- readRDS("~/Desktop/stan_block653")
# Posterior Means 
bs <- as.matrix(extract(fit)$beta) 
bpos <- colMeans(bs)

# Calculate True beta
true <- gwas_block$ES_Derived - wloadings %*% bpos
gwas_block$true <- true

# Plot
ggplot(gwas_block, aes(x=RAF,y=abs(true), col = Risk_Derived)) + geom_point()
ggplot(gwas_block, aes(x=ES_Derived,y=true, col = Risk_Derived)) + geom_point()
```




